# train.py

import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from tqdm import tqdm
import lpips

# π”¥ MRVNet Model Import
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from kadid_volterra_model.mrvnet_unet import MRVNetUNet
from dataset import ImageRestoreDataset
from utils import calculate_psnr, calculate_ssim


def main():
    # β… κ²½λ΅ μ„¤μ •
    CSV_PATH = r"C:\Users\IIPL02\Desktop\MRVNet2D\KADID10K\kadid10k.csv"
    IMG_DIR = r"C:\Users\IIPL02\Desktop\MRVNet2D\KADID10K\images"
    CHECKPOINT_DIR = r"C:\Users\IIPL02\Desktop\MRVNet2D\checkpoints\kadid_volterras"
    os.makedirs(CHECKPOINT_DIR, exist_ok=True)

    # β… ν•μ΄νΌνλΌλ―Έν„° μ„¤μ •
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    BATCH_SIZE = 2
    NUM_EPOCHS = 100
    LEARNING_RATE = 1e-5
    BASE_CHANNELS = 32
    SHIFT_RADIUS = 1
    RANK = 2
    LPIPS_WEIGHT = 0.1

    # β… λ°μ΄ν„°μ…‹ λ΅λ”©
    train_dataset = ImageRestoreDataset(csv_path=CSV_PATH, img_dir=IMG_DIR)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)

    # β… λ¨λΈ, μ†μ‹¤ν•¨μ, μµν‹°λ§μ΄μ € μ •μ
    model = MRVNetUNet(in_channels=3, base_channels=BASE_CHANNELS, shift_radius=SHIFT_RADIUS, rank=RANK).to(DEVICE)
    mse_criterion = nn.MSELoss()
    lpips_fn = lpips.LPIPS(net='alex').to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # β… ν•™μµ λ£¨ν”„
    for epoch in range(1, NUM_EPOCHS + 1):
        model.train()
        epoch_loss = 0.0

        loop = tqdm(train_loader, total=len(train_loader), desc=f"[Epoch {epoch}]")
        for dist_img, ref_img in loop:
            dist_img = dist_img.to(DEVICE)
            ref_img = ref_img.to(DEVICE)

            optimizer.zero_grad()
            output = model(dist_img)

            output_lpips = (output * 2) - 1
            ref_lpips = (ref_img * 2) - 1

            mse_loss = mse_criterion(output, ref_img)
            lpips_loss = lpips_fn(output_lpips, ref_lpips).mean()
            loss = mse_loss + LPIPS_WEIGHT * lpips_loss

            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()
            loop.set_postfix(loss=loss.item())

        avg_loss = epoch_loss / len(train_loader)
        print(f"β… [Epoch {epoch}] Average Loss: {avg_loss:.6f}")

        # β… Epoch λλ‚κ³  ν‰κ°€
        model.eval()
        with torch.no_grad():
            total_psnr = 0
            total_ssim = 0
            for dist_img, ref_img in train_loader:
                dist_img = dist_img.to(DEVICE)
                ref_img = ref_img.to(DEVICE)
                output = model(dist_img)

                psnr = calculate_psnr(output, ref_img)
                ssim = calculate_ssim(output, ref_img)

                total_psnr += psnr
                total_ssim += ssim

            avg_psnr = total_psnr / len(train_loader)
            avg_ssim = total_ssim / len(train_loader)
            print(f"β… [Epoch {epoch}] PSNR: {avg_psnr:.2f} dB, SSIM: {avg_ssim:.4f}")

        # β… μ²΄ν¬ν¬μΈνΈ μ €μ¥
        save_path = os.path.join(CHECKPOINT_DIR, f"mrvnet_epoch{epoch}.pth")
        torch.save(model.state_dict(), save_path)
        print(f"β… Checkpoint saved at {save_path}")

# π”¥ μ§„μ§ μ¤‘μ”ν• λ¶€λ¶„ π”¥
if __name__ == "__main__":
    main()