# train.py
# Distorted ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ í•˜ê³ , Reference ì´ë¯¸ì§€ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ í•˜ëŠ” supervised í•™ìŠµ ë°©ì‹

# ì „ì²´í•™ìŠµì½”ë“œ
""" import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

from mrvnet_unet import MRVNetUNet
from dataset import ImageRestoreDataset
from utils import calculate_psnr, calculate_ssim

def main():
    # âœ… ì„¤ì •
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    EPOCHS = 100
    BATCH_SIZE = 8
    LEARNING_RATE = 1e-4
    RANK = 4
    USE_LOSSLESS = True

    # âœ… ê²½ë¡œ
    TRAIN_CSV = r"E:\MRVNet2D\dataset\KADID10K\kadid10k.csv"
    IMAGE_ROOT = r"E:\MRVNet2D\dataset\KADID10K\images"
    CHECKPOINT_DIR = r"E:\MRVNet2D\checkpoints\volterra_swinir_hybrid"
    os.makedirs(CHECKPOINT_DIR, exist_ok=True)

    # âœ… ë°ì´í„° ë¡œë”
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor()
    ])
    train_dataset = ImageRestoreDataset(csv_path=TRAIN_CSV, img_dir=IMAGE_ROOT, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)

    # âœ… ëª¨ë¸
    model = MRVNetUNet(
        in_channels=3,
        base_channels=32,
        rank=RANK,
        use_lossless=USE_LOSSLESS,
    ).to(DEVICE)

    # âœ… ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™”
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # âœ… í•™ìŠµ ë£¨í”„
    for epoch in range(EPOCHS):
        model.train()
        epoch_loss = 0

        with tqdm(total=len(train_loader), desc=f"Epoch {epoch+1}/{EPOCHS}") as pbar:
            for inputs, targets in train_loader:
                inputs = inputs.to(DEVICE)    # â† distorted ì´ë¯¸ì§€ (ì…ë ¥)
                targets = targets.to(DEVICE)  # â† reference ì´ë¯¸ì§€ (ì •ë‹µ)

                outputs = model(inputs)
                loss = criterion(outputs, targets)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                pbar.set_postfix(loss=loss.item())
                pbar.update(1)

        print(f"ğŸ“Œ Epoch {epoch+1} Loss: {epoch_loss/len(train_loader):.4f}")

        # âœ… ëª¨ë“  ì—í¬í¬ë§ˆë‹¤ ì €ì¥
        ckpt_path = os.path.join(CHECKPOINT_DIR, f"mrvnet_epoch{epoch+1}.pth")
        torch.save(model.state_dict(), ckpt_path)
        print(f"âœ… Checkpoint saved to {ckpt_path}")

# âœ… Windowsì—ì„œ í•„ìˆ˜
if __name__ == "__main__":
    main()
 """

# ì´ì–´ì„œ í•™ìŠµ ì½”ë“œ
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm

from mrvnet_unet import MRVNetUNet
from dataset import ImageRestoreDataset
from utils import calculate_psnr, calculate_ssim

def main():
    # âœ… ì„¤ì •
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    TOTAL_EPOCHS = 100
    BATCH_SIZE = 8
    LEARNING_RATE = 1e-4
    RANK = 4
    USE_LOSSLESS = True

    # âœ… ê²½ë¡œ
    TRAIN_CSV = r"E:\MRVNet2D\dataset\KADID10K\kadid10k.csv"
    IMAGE_ROOT = r"E:\MRVNet2D\dataset\KADID10K\images"
    CHECKPOINT_DIR = r"E:\MRVNet2D\checkpoints\volterra_swinir_hybrid"
    RESUME_CHECKPOINT = os.path.join(CHECKPOINT_DIR, "mrvnet_epoch29.pth")
    os.makedirs(CHECKPOINT_DIR, exist_ok=True)

    # âœ… ë°ì´í„° ë¡œë”
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor()
    ])
    train_dataset = ImageRestoreDataset(csv_path=TRAIN_CSV, img_dir=IMAGE_ROOT, transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)

    # âœ… ëª¨ë¸ ì •ì˜
    model = MRVNetUNet(
        in_channels=3,
        base_channels=32,
        rank=RANK,
        use_lossless=USE_LOSSLESS,
    ).to(DEVICE)

    # âœ… ì˜µí‹°ë§ˆì´ì € ë° ì†ì‹¤ í•¨ìˆ˜ ì •ì˜
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    criterion = nn.MSELoss()

    # âœ… ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
    start_epoch = 0
    if os.path.exists(RESUME_CHECKPOINT):
        model.load_state_dict(torch.load(RESUME_CHECKPOINT, map_location=DEVICE))
        print(f"ğŸ”„ Checkpoint loaded from {RESUME_CHECKPOINT}")
        start_epoch = 29  # ì´ì–´ì„œ í•™ìŠµí•  ì—í­ (0ë¶€í„° ì‹œì‘ì´ë¯€ë¡œ 29ê¹Œì§€ í•™ìŠµëœ ìƒíƒœ)

    # âœ… í•™ìŠµ ë£¨í”„
    for epoch in range(start_epoch, TOTAL_EPOCHS):
        model.train()
        epoch_loss = 0

        with tqdm(total=len(train_loader), desc=f"Epoch {epoch+1}/{TOTAL_EPOCHS}") as pbar:
            for inputs, targets in train_loader:
                inputs = inputs.to(DEVICE)
                targets = targets.to(DEVICE)

                outputs = model(inputs)
                loss = criterion(outputs, targets)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                pbar.set_postfix(loss=loss.item())
                pbar.update(1)

        print(f"ğŸ“Œ Epoch {epoch+1} Loss: {epoch_loss/len(train_loader):.4f}")

        # âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        ckpt_path = os.path.join(CHECKPOINT_DIR, f"mrvnet_epoch{epoch+1}.pth")
        torch.save(model.state_dict(), ckpt_path)
        print(f"âœ… Checkpoint saved to {ckpt_path}")

# âœ… ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    main()
