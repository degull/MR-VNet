먼저 NR-IQA 무참조 품질 평가란 참조 이미지 없이 이미지 품질을 평가하는 방식으로 __실제 서비스에서 중요한 역할을 하고 있습니다.
하지만 기존의 GAP 기반 연구들은 blur나 noise 등 국지적인 왜곡에 민감하지 못하고, 왜곡 위치나 형태 정보를 잘 반영하지 못하는 한계가 있습니다.
그래서 위치 정보를 반영한 attention과 멀티스케일 특징 추출을 통해 한계를 극복하고자 했습니다.


제안하는 모델 구조입니다.
VGG-16 기반으로 5개의 vgg 블록을 사용해서 다양한 수준의 feature를 추출합니다.

그리고 출력된 특징은 low level feature와 high level feature로 나눠서 전달됩니다.

먼저 low level feature는 coordinate attention을 적용해 위치정보를 보존하고, 중요한 채널과 공간 위치를 강화합니다.





* 먼저 **Low-level Feature**는 **Coordinate Attention**을 통해
  → **왜곡 위치를 명확히 강조**하고,
* **High-level Feature**는 **CPFE → HNCA → Upsampling** 과정을 거쳐
  → **왜곡의 크기나 형태를 반영한 멀티스케일 특징**을 추출합니다.

이렇게 나온 두 feature를 합친 뒤
Regression을 통해 **최종 이미지 품질 점수**를 예측하게 됩니다.

---

### 🔹 **3. 핵심 기법 소개**

**Coordinate Attention**은
가로와 세로 방향의 공간 정보를 분리하여 처리함으로써
**위치 정보를 유지한 채 중요 영역을 강조**합니다.

또한 **CPFE 모듈**은
dilation rate를 다르게 설정한 병렬 conv 구조를 통해
**작은 왜곡부터 넓은 왜곡까지 모두 포괄**할 수 있도록 합니다.

---

### 🔹 **4. 실험 결과**

저희 모델은 **TID2013, CSIQ, KADID10K**와 같은 synthetic 데이터셋뿐 아니라
**SPAQ, KONIQ, LIVE-Challenge**와 같은 real-world 데이터셋에서도
**기존 SOTA 모델을 능가하는 성능**을 기록했습니다.

특히 SRCC 기준 평균 성능에서
기존 ARNIQA보다 높은 **0.971 → 0.977**까지 향상되었습니다.

---

### 🔹 **5. 결론**

본 모델은 위치 기반 attention과 멀티스케일 특징 추출을 결합해
기존 NR-IQA 모델의 단점을 극복하였고,
다양한 환경에서 **강건하고 일반화된 품질 평가 성능**을 보여주었습니다.

---

경청해 주셔서 감사합니다.
혹시 attention 방식이나 distortion type 별 반응 등에 대해 궁금하신 점 있으신가요?

---

필요하시면 이 발표 대본을 영어 버전으로도 제공해드릴 수 있습니다.
또는 포스터에 맞춰 프롬프터 형식으로 요약본도 만들어드릴 수 있어요.
